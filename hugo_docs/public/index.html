<!doctype html>
<html lang="en">
  <head>
	<meta name="generator" content="Hugo 0.123.7"><script src="/agentic/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=agentic/livereload" data-no-instant defer></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tuntun Go Agentic Chatbot</title>
    <link rel="stylesheet" href="http://localhost:1313/agentic/style.css">
    <link rel="icon" type="image/png" href="http://localhost:1313/agentic/favicon.png">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.6.1/mermaid.min.js"></script>
  </head>
  <body>
        <div class="container">
      <h1>ü§ñ Tuntun Go Agentic Chatbot</h1>

      <div class="intro">
        <p>
          <strong>An enterprise-grade, high-concurrency agentic chatbot system built
            in Go.</strong>
          It uses the Gin web framework and LangChainGo to provide a robust,
          intelligent assistant for the financial sector, integrating LLM
          capabilities with real-time financial data, market analysis, and news.
        </p>
      </div>

      <div class="toc">
        <h3>üìã Quick Navigation</h3>
        <ul>
          <li><a href="#architecture">System Architecture</a></li>
          <li><a href="#features">Core Engineering & Features</a></li>
          <li><a href="#tools">Available Tools</a></li>
          <li><a href="#api">API Endpoints</a></li>
          <li><a href="#installation">Installation & Setup</a></li>
          <li><a href="#configuration">Configuration</a></li>
          <li><a href="#usage">Usage & Testing</a></li>
          <li><a href="#development">Development</a></li>
          <li><a href="#documentation">Documentation</a></li>
        </ul>
      </div>

      <section id="architecture">
        <h2>üèóÔ∏è System Architecture</h2>
        <p>
          The system is a decoupled, two-stage worker pipeline designed for high
          throughput. It separates fast data preparation from slow LLM
          interactions and executes blocking tool calls concurrently to minimize
          latency.
        </p>

        <div class="expandable-section">
          <div class="section-header" onclick="toggleSection(this)">
            <h3>View Complete Architecture Diagram</h3>
            <span class="expand-icon">‚ñº</span>
          </div>
          <div class="section-content">
            <div class="section-inner">
              <div class="mermaid">
  graph TD
    subgraph Client ["Client Interface"]
        UI["üåê Web Frontend / API Client"]
    end
    subgraph AppServer ["‚ö° Application Server (Go Gin)"]
        A["POST /chat/submit"]
        C["GET /chat/stream/:id"]
        Cancel["POST /chat/cancel/:id"]
    end
    subgraph AgenticCore ["ü§ñ Agentic Core Engine"]
        B["üß† Chatbot Manager<br/>(Central State & Broadcast Orchestrator)"]
        SFG["ü§ñ Single-Flight Gate<br/>Is request unique?"]
        D["Request Queue"]
        subgraph RequestWorkerPool ["üîÑ Unified Request Worker Pool"]
            E["Request Worker"]
        end
        subgraph LeaderPath ["üëë Leader's Workflow (Expensive)"]
            Prep["‚öôÔ∏è Leader: Prepare & Execute<br/>(Acquires LLM Concurrency Slot)"]
        end
        Broadcast["üì° Stream Broadcast<br/>(Leader-Generated)"]
        subgraph ToolEngine ["üõ†Ô∏è Tool Engine"]
            T_Standard["Blocking Tools<br/>(e.g., APIs, DBs)"]
            T_Stream["Streaming Tools<br/>(e.g., RAG SSE)"]
        end
        Janitor["üßπ State-Aware Janitor<br/>(Resource Cleanup)"]
    end
    subgraph ExtDeps ["üåç External Dependencies"]
        L["BE Microservices"]
        M["ArangoDB"]
        N["Redis Cache"]
        P["LLM Provider"]
    end
    subgraph Observability ["üî≠ Observability Stack"]
        Vec["Vector"]
        Lok["Loki"]
        Graf["Grafana"]
    end
    %% Flow Definitions
    UI --> A
    UI --> C
    UI --> Cancel
    %% Ingestion and Gating
    A -->|"1. Submit"| B
    B -->|"2. Enqueue"| D
    D -->|"3. Process"| E
    E -->|"4. Route to Manager"| B
    B -->|"5. Gate Request"| SFG
    %% Leader vs. Follower Path
    SFG -->|"Yes (Leader)"| Prep
    SFG -->|"No (Follower)<br/>6b. Subscribe"| Broadcast
    %% Leader's Full Workflow
    Prep -->|"6a. Call Tools"| T_Standard
    Prep -->|"6a. Call Tools"| T_Stream
    T_Standard --> L
    T_Standard --> M
    T_Standard --> N
    Prep -->|"6a. Call LLM"| P
    P -->|"7a. Stream Chunks"| Broadcast
    T_Stream -->|"7a. Stream Chunks"| Broadcast
    %% Delivery and Cleanup
    Broadcast -->|"8. Fan Out Stream"| B
    C -->|"9a. Get Stream"| B
    B -->|"9b. Deliver to Client"| C
    Cancel -->|"Signal"| B
    Janitor -->|"Monitor & Clean"| B
    AppServer -->|"JSON Logs"| Vec
    Vec -->|"Forward"| Lok
    Lok -->|"Query"| Graf
    %% Styling
    classDef clientStyle fill:#cce5ff,stroke:#004085
    classDef serverStyle fill:#d4edda,stroke:#155724
    classDef coreStyle fill:#fff3cd,stroke:#856404
    classDef leaderStyle fill:#f8d7da,stroke:#721c24
    classDef toolStyle fill:#e1d5e7,stroke:#6f42c1
    classDef extStyle fill:#e2f3e4,stroke:#28a745
    classDef janitorStyle fill:#f5c6cb,stroke:#721c24
    classDef queueStyle fill:#d6d8db,stroke:#383d41
    classDef obsStyle fill:#e0e0e0,stroke:#6c757d
    classDef gateStyle fill:#ffc107,stroke:#856404,stroke-width:2px
    classDef broadcastStyle fill:#cceeff,stroke:#007bff,stroke-width:2px
    class UI clientStyle
    class A,C,Cancel serverStyle
    class B,E coreStyle
    class D queueStyle
    class SFG gateStyle
    class Prep leaderStyle
    class Broadcast broadcastStyle
    class T_Standard,T_Stream toolStyle
    class L,M,N,P extStyle
    class Janitor janitorStyle
    class Vec,Lok,Graf obsStyle
              </div>
            </div>
          </div>
        </div>
      </section>

      <section id="features">
        <h2>‚ö° Core Engineering & Features</h2>

        <div class="feature-grid">
          <div class="feature-card">
            <h4>üöÄ Performance & Architecture</h4>
            <ul>
                <li><span class="popup-trigger" onclick="showPopup('two-stage-pipeline')">Two-Stage Pipeline</span></li>
                <li><span class="popup-trigger" onclick="showPopup('concurrent-tool-execution')">Concurrent Tool Execution</span></li>
                <li><span class="popup-trigger" onclick="showPopup('stateful-conversation')">Stateful Conversations</span></li>
                <li><span class="popup-trigger" onclick="showPopup('data-driven-tools')">Data-Driven Tooling</span></li>
            </ul>
          </div>

          <div class="feature-card">
            <h4>üõ°Ô∏è Resource Management</h4>
            <ul>
                <li><span class="popup-trigger" onclick="showPopup('circuit-breakers')">Anti-Fragile Circuit Breakers</span></li>
                <li><span class="popup-trigger" onclick="showPopup('single-flight')">Single-Flight Group</span></li>
                <li><span class="popup-trigger" onclick="showPopup('e2e-stream-broadcasting')">On-Demand Broadcasting</span></li>
                <li><span class="popup-trigger" onclick="showPopup('state-aware-janitor')">State-Aware Janitor</span></li>
                <li><span class="popup-trigger" onclick="showPopup('e2e-cancellation')">End-to-End Cancellation</span></li>
            </ul>
          </div>

          <div class="feature-card">
            <h4>üìä Data Handling & Integrity</h4>
            <ul>
                <li><span class="popup-trigger" onclick="showPopup('token-truncation')">Targeted Token Truncation</span></li>
                <li><span class="popup-trigger" onclick="showPopup('context-aware-caching')">Context-Aware Caching</span></li>
                <li><span class="popup-trigger" onclick="showPopup('rag')">Direct Stream RAG</span></li>
                <li><span class="popup-trigger" onclick="showPopup('automated-indexing')">Automated Schema & Indexing</span></li>
            </ul>
          </div>

          <div class="feature-card">
            <h4>üî≠ Total System Observability</h4>
            <ul>
                <li><span class="popup-trigger" onclick="showPopup('structured-logging')">Structured JSON Logging</span></li>
                <li><span class="popup-trigger" onclick="showPopup('observability')">Complete Observability Stack</span></li>
            </ul>
          </div>
        </div>
      </section>

      <section id="tools">
        <div class="expandable-section">
          <div class="section-header" onclick="toggleSection(this)">
            <h3>üõ†Ô∏è Available Tools</h3>
            <span class="expand-icon">‚ñº</span>
          </div>
          <div class="section-content">
            <div class="section-inner">
              <h4>Market & News Tools</h4>
              <ul>
                <li>
                  <code>realtime_market</code>: Fetches a live snapshot of
                  market data for one or more stocks
                </li>
                <li>
                  <code>historical_marketdata</code>: Retrieves historical price
                  and volume data
                </li>
                <li>
                  <code>news_summary</code>: Fetches the 5 most recent news
                  article summaries
                </li>
                <li>
                  <code>get_current_time</code>: Returns the current date and
                  time
                </li>
              </ul>

              <h4>Valuation & Research Tools</h4>
              <ul>
                <li>
                  <code>stock_valuation</code>: Multi-faceted valuation with
                  quality, fair value, and trading signals
                </li>
                <li>
                  <code>analyze_stock</code>: Qualitative research data
                  (business line, competitive advantage)
                </li>
              </ul>

              <h4>Financial Report Tools</h4>
              <ul>
                <li>
                  <code>financial_annualreport</code>: Annual financial reports
                  over a range of years
                </li>
                <li>
                  <code>financial_quarterreport</code>: Quarterly financial
                  reports
                </li>
                <li>
                  <code>financial_ttmreport</code>: Trailing Twelve Month (TTM)
                  values
                </li>
                <li>
                  <code>financial_ytdreport</code>: Year-to-Date (YTD)
                  cumulative values
                </li>
              </ul>

              <h4>Financial Ratio Tools</h4>
              <ul>
                <li>
                  <code>financial_profitability_ratio</code>: ROA TTM, ROE TTM,
                  etc.
                </li>
                <li>
                  <code>financial_solvency_ratio</code>: Current Ratio, Debt
                  equity ratio, etc.
                </li>
                <li>
                  <code>financial_valuation_ratio</code>: PER (TTM), PBV (YTD),
                  etc.
                </li>
                <li>
                  <code>financial_dividend_ratio</code>: Dividend (TTM), Payout
                  Ratio, etc.
                </li>
              </ul>

              <h4>Knowledge & Support Tools</h4>
              <ul>
                <li>
                  <code>frequently_asked</code>:
                  <strong>(Direct Stream Path)</strong> Answers general
                  questions by streaming directly from RAG pipeline
                </li>
              </ul>
            </div>
          </div>
        </div>
      </section>

      <section id="api">
        <div class="expandable-section">
          <div class="section-header" onclick="toggleSection(this)">
            <h3>üîå API Endpoints</h3>
            <span class="expand-icon">‚ñº</span>
          </div>
          <div class="section-content">
            <div class="section-inner">

              <h4>Authentication</h4>
              <p>
                Protected endpoints under the <code>/chat</code> group require
                an <code>X-API-Key</code> header matching the configured
                environment variable.
              </p>
              <hr>

              <h4>Endpoints Summary</h4>
              <ul>
                <li>
                  <code>POST /chat/submit</code>: (Auth) Submits a query,
                  returns a <code>request_id</code>
                </li>
                <li>
                  <code>GET /chat/stream/:request_id</code>: (Public)
                  Establishes SSE connection to stream response
                </li>
                <li>
                  <code>POST /chat/cancel/:request_id</code>: (Public) Cancels
                  an in-progress request
                </li>
                <li>
                  <code>POST /chat/update_reaction</code>: (Auth) Updates user
                  feedback for a response
                </li>
                <li>
                  <code>GET /chat/get_chat_history</code>: (Auth) Retrieves
                  conversation history
                </li>
              </ul>
            </div>
          </div>
        </div>
      </section>

      <section id="installation">
        <div class="expandable-section">
          <div class="section-header" onclick="toggleSection(this)">
            <h3>üöÄ Installation & Setup</h3>
            <span class="expand-icon">‚ñº</span>
          </div>
          <div class="section-content">
            <div class="section-inner">
              <h4>Prerequisites</h4>
              <ul>
                <li>Go 1.24.0</li>
                <li>Redis Server</li>
                <li>ArangoDB</li>
                <li>Docker & Docker Compose</li>
                <li>A configured <code>.env</code> file</li>
              </ul>
              <hr>

              <h4>Running with Docker Compose (Recommended)</h4>
              <p>This is the canonical way to run the entire system:</p>
              <ol>
                <li>Clone the repository</li>
                <li>Create your <code>.env</code> file from the template</li>
                <li>Launch everything:</li>
              </ol>
              <pre><code>docker-compose up --build</code></pre>
              <p>This single command will:</p>
              <ul>
                <li>Build the Go application container</li>
                <li>Start ArangoDB, Redis, Loki, Grafana, and Vector</li>
                <li>Chatbot available at <code>http://localhost:8080</code></li>
                <li>Grafana available at <code>http://localhost:3000</code></li>
              </ul>
              <hr>

              <h4>Manual Local Setup</h4>
              <ol>
                <li>Clone repo and <code>cd</code> into it</li>
                <li>Install dependencies: <code>go mod tidy</code></li>
                <li>Configure <code>.env</code></li>
                <li>
                  Run services: Ensure Redis, ArangoDB, and dependent
                  microservices are running
                </li>
                <li>Run app: <code>go run main.go</code></li>
              </ol>
            </div>
          </div>
        </div>
      </section>

      <section id="configuration">
        <div class="expandable-section">
          <div class="section-header" onclick="toggleSection(this)">
            <h3>‚öôÔ∏è Configuration (.env file)</h3>
            <span class="expand-icon">‚ñº</span>
          </div>
          <div class="section-content">
            <div class="section-inner">
              <p>
                This file is critical for tuning system performance and
                behavior.
              </p>
              <pre><code>
# LLM Configuration
LLM_TYPE=DEEPSEEK # Options: OPENAI, DEEPSEEK, OLLAMA
DEEPSEEK_API_KEY=sk-your-deepseek-key
OPENAI_API_KEY=sk-your-openai-key
PROMPT_VERSION=v1                   # System Prompt used
TOOL_SELECTION_PROMPT_VERSION=v1    # Tool Selection Prompt used

# --- Token & Output Management ---
MAX_LLM_INPUT_TOKENS=40000          # Max tokens the LLM accepts as input.
MAX_TOTAL_TOOL_OUTPUT_TOKENS=33000  # Max combined tokens from all tools before truncation.
LONG_TEXT_TOOLS=analyze_stock       # Comma-separated list of tools to truncate first.

# --- Pipeline, Concurrency & Lifecycle Tuning ---
# These settings dictate the performance and resilience of the system. Handle them with care.
MAX_CONCURRENT_REQUESTS=10          # Number of workers in the fast data-prep pool. Higher = more concurrent request processing.
MAX_CONCURRENT_LLM_STREAMS=5        # Number of workers in the slow LLM-interaction pool. Keep this low to avoid hitting API rate limits.
HISTORY_ITEMS=3                     # Number of past conversation turns to include in the context.
QUEUE_SIZE=100                      # Buffer size for requests between pipeline stages.
STREAM_TOKEN_BUFFER=100             # Buffer for the final SSE stream to the client.

# --- State-Aware Janitor & Timeouts ---
JANITOR_INTERVAL=2m                 # How often The Wolf from Pulp Fiction shows up to clean the mess.
PROCESSING_TIMEOUT=10m              # The bomb timer in Mission: Impossible. Max time a dequeued request can run before being killed. Kills stuck jobs.
QUEUE_TIMEOUT=1h                    # Max time a request can wait in the queue before being discarded. A safety net for extreme load.
TOOL_TIMEOUT=30s                    # Max execution time for a single tool call. Prevents a slow dependency from stalling everything.
CLIENT_PICKUP_TIMEOUT=1s            # Grace period for the client to connect to the stream. Solves a race condition for fast/cached responses. MUST be short.
SUBMIT_TIMEOUT=2s                   # The bouncer's patience. Max time to wait for a spot in the main request queue before rejecting the request. Prevents callers from hanging on a full system.

# --- Caching & Direct Streaming ---
REDIS_URL=redis://localhost:6379
TIMEBOUND_TOOLS=realtime_market,get_current_time # Comma-separated list of tools whose results are never cached.
NATURAL_ANSWER_TOOLS=frequently_asked            # Comma-separated list of tools that activate the Direct Stream Path, bypassing the second LLM call. This is a critical performance setting.

# ArangoDB Configuration
LOG_DB_URL=http://localhost:8529
LOG_DB_USERNAME=root
LOG_DB_PASSWORD=your_arangodb_password
LOG_DB_NAME=tuntun_chatbot_v2
LOG_DB_TEST_NAME=tuntun_chatbot_test
LOG_DB_COLLECTION_NAME=chat_logs
RESEARCH_DB_COLLECTION_NAME=research_report

# --- API Server & Backend Services ---
API_HOST=0.0.0.0
API_PORT=8080
API_KEY=your-secret-api-key

# Backend Service Endpoints (direct http://... or service discovery consul://...)
CONSUL_ADDR=127.0.0.1:8500
BE_FAIR_VALUE_URL=http://...
BE_TRADING_SIGNAL_URL=http://...
BE_COMPANY_QUALITY_URL=http://...
BE_ORDERBOOK_HEADER_URL=http://...
BE_PRICE_SUMMARY_URL=http://...
BE_FINANCIAL_DATA_URL=http://...
BE_FINANCIAL_DATA_ALL_QUARTER_URL=http://...
BE_HISTORICAL_MARKET_DATA_URL=http://...
BE_NEWS_LATEST_URL=http://...
# This endpoint is now called directly from the `frequently_asked` streaming tool.
TENCENT_RAG_URL=https://...
TENCENT_RAG_BOT_APP_KEY=...
</code></pre>
            </div>
          </div>
        </div>
      </section>

      <section id="usage">
        <div class="expandable-section">
          <div class="section-header" onclick="toggleSection(this)">
            <h3>üéØ Usage & Testing</h3>
            <span class="expand-icon">‚ñº</span>
          </div>
          <div class="section-content">
            <div class="section-inner">
              <h4>Running the Application</h4>
              <pre><code>go run main.go</code></pre>
              <p>
                The server starts on the configured host and port (default <code>http://localhost:8080</code>).
              </p>

              <hr>

              <h4>Advanced Concurrency Testing</h4>
              <p>These scripts and tests allow you to validate the system's core concurrency and resilience models.</p>

              <h4>1. Testing General Throughput (<code>test_concurrency</code>)</h4>
              <p>This script validates that the server can handle many <em>different</em> requests in parallel, testing the capacity of the worker pools.</p>
              <ol>
                <li>
                  <strong>Run the test:</strong>
                  <pre><code># Usage: go run ./cmd/test_concurrency -n &lt;num_requests&gt; -w &lt;server_workers&gt;
go run ./cmd/test_concurrency -n 20 -w 10</code></pre>
                </li>
                <li>
                  <strong>Analyze results:</strong> The script generates an Excel file like <code>test_results/parallel_test_r20_w10.xlsx</code>. Check that all requests completed and the Time-To-First-Token (TTF) values are reasonable.
                </li>
              </ol>

              <h4>2. Testing End-to-End Broadcast & Single-Flight Protection (<code>test_single_flight</code>)</h4>
              <p>This test validates the complete end-to-end request deduplication strategy by sending many <em>identical</em> requests simultaneously. It confirms that the <span class="popup-trigger" onclick="showPopup('single-flight')">preparation-phase single-flight</span> and the <span class="popup-trigger" onclick="showPopup('e2e-stream-broadcasting')">streaming-phase broadcast</span> work together perfectly to handle a "thundering herd" scenario.</p>
              <ol>
                <li>
                  <strong>(Optional but Recommended)</strong> Clear the relevant Redis cache key before testing (e.g., <code>redis-cli DEL "ai_chatbot_conv:..."</code>) to ensure you are not just hitting the cache and are testing a live LLM broadcast.
                </li>
                <li>
                  <strong>Run the test:</strong>
                   <pre><code># Usage: go run ./cmd/test_single_flight -n &lt;num_requests&gt;
go run ./cmd/test_single_flight -n 10</code></pre>
                </li>
                <li>
                  <strong>Analyze Server Logs:</strong> The proof of the <strong>preparation-phase</strong> single-flight is in the server logs. Look for:
                  <ul>
                      <li>One log message saying <code>"No active broadcaster found. This request is the LEADER. Forging the Ring."</code> (the leader).</li>
                      <li>Nine (or N-1) messages saying <code>"This request is a FOLLOWER. Joining existing broadcast."</code> (the followers).</li>
                  </ul>
                </li>
                <li>
                  <strong>Analyze Excel Results:</strong> The proof of the <strong>streaming-phase</strong> broadcast is in the generated <code>test_results/broadcast_test_r10.xlsx</code> file:
                  <ul>
                    <li><strong>Data Integrity:</strong> Verify that the <code>Full Response</code> column is <strong>identical</strong> for all 10 requests. This proves everyone received the same data.</li>
                    <li><strong>Synchronized Lifetime:</strong> Check that the <code>API Call Duration (s)</code> is the same for all requests. This proves they were all tethered to a single underlying stream.</li>
                    <li><strong>TTF Variance:</strong> Observe the slight variations in <code>Client-Side TTF (s)</code>. This is not a bug; it is <strong>proof</strong> that the "late subscriber" and "history replay" mechanisms are working, as follower clients catch up to the broadcast that has already started.</li>
                  </ul>
                </li>
              </ol>

              
              <h4>3. Testing End-to-End Cancellation (<code>stream_test.go</code>)</h4>
              <p>This integration test suite rigorously validates the <span class="popup-trigger" onclick="showPopup('e2e-cancellation')">End-to-End Cancellation</span> resilience feature. It confirms that a request can be terminated at any point in its lifecycle and that the system reclaims resources gracefully and predictably. This is crucial for preventing resource leaks from abandoned requests.</p>
              <p>The test simulates every possible cancellation scenario:</p>
              <ul>
                <li><strong>Happy Path:</strong> A standard request streams to completion without interruption.</li>
                <li><strong>Pre-emptive Cancellation:</strong> A request is cancelled <strong>immediately</strong> after submission, before the client even connects to the stream. The test verifies that the server correctly returns a <code>cancelled</code> status.</li>
                <li><strong>Mid-Stream Cancellation:</strong> The most critical test. It uses a goroutine to begin streaming, then sends a cancellation request from a parallel thread, proving that the <code>context</code> correctly terminates the in-progress work.</li>
                <li><strong>Post-Completion Cancellation:</strong> The test waits for a stream to finish and for the server to fully close the connection. It then attempts to cancel the now-nonexistent request and verifies the server correctly returns a <code>not_found</code> status, proving proper state management and cleanup.</li>
              </ul>
              <ol>
                <li>
                  <strong>Run the test:</strong>
                   <pre><code># This command specifically runs all tests prefixed with "TestStream"
go test -v -run ^TestStream .</code></pre>
                </li>
                <li>
                  <strong>Analyze results:</strong> Observe the test logs. A successful run will show each scenario being executed with a final <code>‚úÖ Test Passed</code> message, confirming that the system handles all cancellation states correctly.
                </li>
              </ol>
              <hr>

              <h4>Running Standard Tests</h4>
              <p>To run endpoint tests and stream-cancel tests:</p>
              <pre><code>go test -v .</code></pre>
              <p>To run all tools tests:</p>
              <pre><code>go test -v ./tools/tooltest -run TestAllTools</code></pre>

              <hr>

              <h4>Running Endpoint Health Checks</h4>
              <p>To diagnose external API connections without running the full test suite:</p>
              <pre><code>chmod +x run_health_checks.sh
./run_health_checks.sh tools/tooltest/extapi/&lt;tool&gt;.go</code></pre>
              <p>For example, for testing the valuation tool external apis:</p>
              <pre><code>./run_health_checks.sh tools/tooltest/extapi/valuation.go</code></pre>
              <p>All Go files inside <code>tools/tooltest/extapi</code> correlates to each tool files (inside <code>toolbe</code> and <code>toolnonbe</code> dir) and can be used for healthcheck.</p>
            </div>
          </div>
        </div>
      </section>

      <section id="development">
        <div class="expandable-section">
          <div class="section-header" onclick="toggleSection(this)">
            <h3>üë®‚Äçüíª Development</h3>
            <span class="expand-icon">‚ñº</span>
          </div>
          <div class="section-content">
            <div class="section-inner">
              <h4>Project Structure</h4>
              <pre><code>
tuntun-go-chatbot/
‚îú‚îÄ‚îÄ chatbot/                # Core agentic logic (manager, preparer, streamer)
‚îú‚îÄ‚îÄ cmd/                    # Standalone utility commands
‚îú‚îÄ‚îÄ config/                 # Environment variable loading & validation
‚îú‚îÄ‚îÄ core/                   # LLM model & core services initialization
‚îú‚îÄ‚îÄ db/                     # Database clients (ArangoDB, Redis)
‚îú‚îÄ‚îÄ frontend/               # Demo UI
‚îú‚îÄ‚îÄ tools/                  # All tool definitions and implementations
‚îÇ   ‚îú‚îÄ‚îÄ toolbe/             # Tuntun Backend-dependent tool implementations
‚îÇ   ‚îú‚îÄ‚îÄ toolnonbe/          # Non-Tuntun Backend-dependent tool implementations
‚îÇ   ‚îú‚îÄ‚îÄ toolcore/           # Core logic for tool registration and invocation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ caller.go       # Orchestrates concurrent tool execution & direct stream path
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ definitions.go  # Single source of truth for all tool definitions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dynamic.go      # Implementation of DynamicTool used in definitions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.go      # Declaration of reusable input tools schemas
‚îÇ   ‚îú‚îÄ‚îÄ tooltest/           # Unit and integration tests for all tools
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ extapi/         # Standalone health checks for external APIs
‚îÇ   ‚îú‚îÄ‚îÄ tooltypes/          # Shared Go structs for tool arguments and responses
‚îÇ   ‚îî‚îÄ‚îÄ toolutils/          # Reusable helper functions for tools
‚îú‚îÄ‚îÄ types/                  # Core application-wide data structures
‚îú‚îÄ‚îÄ .env                    # Environment variables customization
‚îú‚îÄ‚îÄ go.mod                  # Go module definitions
‚îú‚îÄ‚îÄ main.go                 # Application entry point and Gin server setup
‚îú‚îÄ‚îÄ docker-compose.yml      # Orchestrates all services for production
‚îî‚îÄ‚îÄ README.md
              </code></pre>
              <h4>Adding a New Tool</h4>
              <ol>
                <li>
                  <strong>(Optional) Implement Logic:</strong> Create the core
                  function in <code>toolbe/</code> or <code>toolnonbe/</code>
                </li>
                <li>
                  <strong>Define the Tool:</strong> Modify
                  <code>tools/toolcore/definitions.go</code> and add to
                  <code>allTools</code> slice
                </li>
                <li>
                  <strong>Add Tests:</strong> Create test in
                  <code>tools/tooltest/</code> and healthcheck in
                  <code>tools/tooltest/extapi/</code>
                </li>
              </ol>
            </div>
          </div>
        </div>
      </section>

      
      <section id="documentation">
        <h2>üìö Documentation & Deep Dives</h2>
        <div class="intro">
          <p>
            This page provides a high-level overview. For detailed architectural breakdowns, technical narratives, and implementation guides, explore the full documentation site.
          </p>
          <p style="text-align:center; margin-top: 20px;">
            <a href="docs/" class="cta-button">Explore Full Documentation</a>
          </p>
        </div>
      </section>

    </div>

    
    <div id="popup-modal" class="modal">
      <div class="modal-content">
        <span class="close" onclick="closePopup()">√ó</span>
        <div id="popup-content"></div>
      </div>
    </div>

    <script>
      
      mermaid.initialize({
        startOnLoad: true,
        theme: "base",
        themeVariables: {
          primaryColor: "#667eea",
          primaryTextColor: "#333",
          primaryBorderColor: "#764ba2",
          lineColor: "#666",
          secondaryColor: "#a8edea",
          tertiaryColor: "#fed6e3",
        },
      });

      function toggleSection(header) {
        const section = header.parentElement;
        const content = section.querySelector(".section-content");
        const icon = header.querySelector(".expand-icon");

        if (content.classList.contains("expanded")) {
          content.classList.remove("expanded");
          section.classList.remove("expanded");
          icon.style.transform = "rotate(0deg)";
        } else {
          content.classList.add("expanded");
          section.classList.add("expanded");
          icon.style.transform = "rotate(180deg)";
        }
      }

      function showPopup(type) {
        const modal = document.getElementById("popup-modal");
        const content = document.getElementById("popup-content");

        let popupContent = "";

        switch (type) {
          case "two-stage-pipeline":
            popupContent = `
                        <h2>üîÑ Two-Stage Pipeline</h2>
                        <p>Decouples fast data-prep workers from slow LLM-streaming workers using two independent, semaphore-limited worker pools (<code>prepare</code> -> <code>stream</code>). This prevents slow LLM API calls from blocking new incoming requests, maximizing throughput.</p>
                        <hr>
                        <p><strong>Benefits:</strong></p>
                        <ul>
                            <li>New requests don't wait for slow LLM calls</li>
                            <li>Higher system throughput under load</li>
                            <li>Better resource utilization</li>
                            <li>Prevents cascading delays</li>
                        </ul>
                    `;
            break;

          case "rag":
            popupContent = `
                        <h2>üöÄ Direct Stream RAG</h2>
                        <p>For designated <code>NATURAL_ANSWER_TOOLS</code> like knowledge base queries, the system activates a special RAG path. This bypasses the final LLM synthesis step, streaming the response from the knowledge tool directly to the user.</p>
                        <hr>
                        <p><strong>Standard Flow:</strong> User Query ‚Üí LLM Selects Tools ‚Üí Execute Tools ‚Üí LLM Synthesizes Answer from Tool Output</p>
                        <hr>
                        <p><strong>Direct Stream Flow:</strong> User Query ‚Üí LLM Selects RAG Tool ‚Üí Execute RAG Tool ‚Üí Stream Tool Output Directly to User</p>
                        <hr>
                        <p><strong>Benefits:</strong></p>
                        <ul>
                            <li><strong>Lower Latency:</strong> Skips an entire LLM round-trip.</li>
                            <li><strong>Reduced Cost:</strong> Saves on expensive LLM synthesis API calls.</li>
                            <li><strong>Higher Fidelity:</strong> Delivers raw, unfiltered information directly from the source of truth.</li>
                        </ul>
                    `;
            break;

          case "automated-indexing":
            popupContent = `
                        <h2>‚öôÔ∏è Automated Schema & Indexing</h2>
                        <p>On every startup, the application runs an <code>initializeSchema</code> function (in <code>db/arango.go</code>) that verifies and creates the necessary database schema. This isn't just about creating tables; its most critical role is to <strong>guarantee that performance-critical indexes exist</strong>.</p>
                        <p>This prevents a common production issue where queries are slow after a fresh deployment because a required index is missing. The system ensures optimal performance from the very first request.</p>
                        <hr>
                        <p><strong>Ensured Indexes:</strong></p>
                        <ul>
                            <li><strong><code>idx_log_user_time</code>:</strong> A persistent index on <code>user_id</code> and <code>user_query_timestamp</code>. This makes retrieving a user's chat history (<code>GetChatHistory</code>) extremely fast, avoiding slow full-collection scans.</li>
                            <li><strong><code>idx_log_request_id</code>:</strong> A unique hash index on <code>request_id</code>. This allows for instantaneous lookups when a user submits a reaction (<code>UpdateReaction</code>), turning a slow search into a direct pointer access.</li>
                            <li><strong><code>idx_research_stock_code</code>:</strong> A unique hash index on <code>stock_code</code>. This provides near-instant retrieval of research documents (<code>GetResearchDocByStockCode</code>), which is critical for <strong>analyze_stock</strong> tool.</li>
                        </ul>
                        <hr>
                        <p><strong>Benefits:</strong></p>
                        <ul>
                            <li><strong>Guaranteed Performance:</strong> Queries are fast from the moment the application starts.</li>
                            <li><strong>Deployment Safety:</strong> Prevents code from running against an un-indexed database, avoiding surprise performance bottlenecks in production.</li>
                            <li><strong>Self-Healing:</strong> If an index is accidentally deleted, it is automatically recreated on the next restart.</li>
                        </ul>
                    `;
            break;

          case "circuit-breakers":
            popupContent = `
                        <h2>üõ°Ô∏è Anti-Fragile Circuit Breakers</h2>
                        <p>Every critical external dependency (LLM, Redis, ArangoDB) is wrapped in its own circuit breaker to prevent cascading failures.</p>
                        <div class="mermaid">
graph TD
    subgraph Normal["Normal Operation (Closed)"]
        direction LR
        Req1[Request] -->|Success| Dep1[Dependency]
        Dep1 -->|OK| Req1
    end

    subgraph FailureDetection["Failure Detection (Closed)"]
        direction LR
        Req2[Request] -->|Failure 1| Dep2[Dependency]
        Dep2 -.->|"Timeout/Error"| Req2
        Req3[Request] -->|Failure 2| Dep2
        Dep2 -.->|"Timeout/Error"| Req3
    end

    subgraph CircuitOpen["Circuit Open"]
        direction LR
        CB_Open["Circuit Breaker<br/>(State: OPEN)"]
        Req5[Request] -.->|"Fail Fast"| CB_Open
        CB_Open -->|"ErrOpenState"| Req5
    end

    subgraph HalfOpen["Recovery Attempt (Half-Open)"]
        direction LR
        CB_Half["Circuit Breaker<br/>(State: HALF-OPEN)"]
        Req7[Request] -->|Test Request| Dep3[Dependency]
    end

    Normal ==>|"Failures Within Sliding-Window"| FailureDetection
    FailureDetection ==>|"Threshold Met"| CircuitOpen
    CircuitOpen ==>|"Cooldown Expires"| HalfOpen
    HalfOpen ==>|"Success (Reset)"| Normal
    HalfOpen ==>|"Failure (Re-Open)"| CircuitOpen

    classDef normal fill:#d4edda,stroke:#155724
    classDef failing fill:#f8d7da,stroke:#721c24
    classDef open fill:#f5c6cb,stroke:#721c24,color:#000
    classDef halfopen fill:#fff3cd,stroke:#856404
    class Normal,Dep1,Req1 normal; class FailureDetection,Dep2,Req2,Req3 failing; class CircuitOpen,CB_Open,Req5 open; class HalfOpen,CB_Half,Dep3,Req7 halfopen;
                        </div>
                        <p>When a dependency fails repeatedly, the circuit "opens," causing subsequent calls to fail instantly without tying up resources. After a cooldown, it enters a "half-open" state to test for recovery.</p>
                        <hr>
                        <p><strong>Benefits:</strong></p>
                        <ul>
                            <li>Prevents worker pool exhaustion during outages.</li>
                            <li>Protects against cascading system failures.</li>
                            <li>Allows the system to remain responsive for other requests.</li>
                            <li>Enables intelligent, automatic recovery.</li>
                        </ul>
                    `;
            break;

          case "concurrent-tool-execution":
            popupContent = `
                <h2>‚ö° Concurrent Tool Execution</h2>
                <p>The system leverages Go's powerful concurrency model (goroutines) to execute multiple tool calls in parallel. Instead of waiting for each tool to finish sequentially, it launches all tool calls at once and waits for them all to complete.</p>
                <div class="mermaid">
graph TD
    subgraph Old ["Traditional Serial Execution"]
        A[Start]
        T1["Tool 1 (3s)"]
        T2["Tool 2 (1s)"]
        T3["Tool 3 (2s)"]
        E[End]
        TotalS["Total Time: 6s"]
    end

    subgraph New ["Concurrent Execution"]
        B[Start]
        P1["Tool 1 (3s)"]
        P2["Tool 2 (1s)"]
        P3["Tool 3 (2s)"]
        F[End]
        TotalP["Total Time: 3s"]
    end

    %% Flow Definitions
    A --> T1 --> T2 --> T3 --> E --> TotalS
    B --> P1; B --> P2; B --> P3
    P1 --> F; P2 --> F; P3 --> F
    F --> TotalP

    %% Styling
    classDef startEndStyle fill:#d4edda,stroke:#155724
    classDef toolStyle fill:#cce5ff,stroke:#004085
    classDef totalStyle fill:#f8d7da,stroke:#721c24

    class A,E,B,F startEndStyle
    class T1,T2,T3,P1,P2,P3 toolStyle
    class TotalS,TotalP totalStyle
                </div>
                <p>This is implemented in <code>toolutils.ExecuteToolsInParallel</code> using a <code>sync.WaitGroup</code> to manage the goroutines.</p>
                <hr>
                <p><strong>Benefit:</strong> Drastically reduces data-gathering latency. The total wait time is determined by the <strong>slowest single tool</strong>, not the sum of all tool execution times.</p>
            `;
            break;

        case "stateful-conversation":
            popupContent = `
                <h2>üß† Stateful Conversations</h2>
                <p>To provide contextually relevant answers, the chatbot maintains conversation history. Before processing a new query, it fetches the last <code>N</code> turns of the conversation (configurable via <code>HISTORY_ITEMS</code>) from ArangoDB.</p>
                <p>This history is formatted and injected into the LLM prompt, giving the model the necessary context to understand follow-up questions and references to previous messages.</p>
                <p><strong>Code Logic:</strong> The <code>preparer.fetchAndFormatHistory</code> function retrieves data using <code>arangoStore.GetChatHistory</code> and builds a string like:</p>
                <pre><code>Human: What is the market cap of AAPL?
Assistant: The market cap for AAPL is $2.8T.
Human: What about for GOOGL?
Assistant: The market cap for GOOGL is $1.7T.</code></pre>
                <hr>
                <p><strong>Benefit:</strong> Enables natural, multi-turn dialogues and a more intelligent, human-like user experience.</p>
            `;
            break;

        case "single-flight":
            popupContent = `
                        <h2>üõ°Ô∏è Single-Flight Group (Sauron)</h2>
                        <p>This is the first layer of Sauron's defense against the "thundering herd" problem. When multiple, identical requests arrive, Go's <code>singleflight.Group</code> is exploited to ensure only the <strong>first</strong> request (the Leader) forges the broadcast infrastructure.</p>
                        <div class="mermaid">
graph TD
    subgraph After ["Sauron's Dominion"]
        R4["Follower Req"]
        R5["Follower Req"]
        R6["Leader Req"]
        SF{"üëÅÔ∏è singleflight.Group<br/>(The Eye of Sauron)"}
        W4["Leader's Worker"]
        Broadcast["üöÄ On-Demand Broadcast"]
    end

    %% Flow Definitions
    R4 --> SF; R5 --> SF; R6 --> SF
    SF -->|"One Ring to rule them all..."| W4
    W4 -->|"...and in the darkness bind them"| Broadcast
    Broadcast -->|"Share power"| SF
    SF -->|"Enslave all"| R4 & R5 & R6

    %% Styling
    classDef reqStyle fill:#cce5ff,stroke:#004085
    classDef workerStyle fill:#d4edda,stroke:#155724
    classDef sfStyle fill:#ffb366,stroke:#e65c00,color:#000
    classDef broadcastStyle fill:#e1d5e7,stroke:#6f42c1

    class R4,R5,R6 reqStyle
    class W4 workerStyle
    class SF sfStyle
    class Broadcast broadcastStyle
                        </div>
                        <p>All other identical requests (the Followers) do no work. They are held captive by the single-flight and, upon its completion, are given a handle to the one true broadcast forged by their Leader. This is visible in the logs: one <code>"This request is the LEADER"</code> followed by many <code>"This request is a FOLLOWER"</code> messages.</p>
                        <hr>
                        <p>This pattern is the key to creating the broadcast on-demand, forming the foundation for the ultimate weapon: <span class="popup-trigger" onclick="showPopup('e2e-stream-broadcasting')">On-Demand Stream Broadcasting</span>.</p>
                    `;
            break;

        case "e2e-stream-broadcasting":
            popupContent = `
                        <h2>üöÄ On-Demand Broadcasting (Sauron)</h2>
                        <p>This is Sauron's ultimate weapon against waste and inefficiency. Forged on-demand by the <span class="popup-trigger" onclick="showPopup('single-flight')">single-flight leader</span>, it ensures that for any number of identical requests, only one expensive LLM stream is ever created. It is the One Ring of stream management.</p>
                        <div class="mermaid">
graph TD
    subgraph Old ["The Age of Men (Wasteful)"]
        Req1["Identical Req A"] --> LLM1["üî• Expensive LLM Stream 1"]
        Req2["Identical Req B"] --> LLM2["üî• Expensive LLM Stream 2"]
        Req3["Identical Req C"] --> LLM3["üî• Expensive LLM Stream 3"]
    end
    subgraph New ["The Age of the Orc (Sauron's Dominion)"]
        Leader["Leader Req A"] --> LLM4["‚úÖ One LLM Stream to Rule Them All"]
        LLM4 -- "feeds" --> Broadcaster["One Ring<br/>(StreamBroadcaster)"]
        FollowerB["Follower Req B"] -- "subscribes & obeys" --> Broadcaster
        FollowerC["Follower Req C"] -- "subscribes & obeys" --> Broadcaster
    end

    %% Styling
    classDef reqStyle fill:#cce5ff,stroke:#004085
    classDef llmStyle fill:#f8d7da,stroke:#721c24
    classDef goodLlmStyle fill:#d4edda,stroke:#155724
    classDef broadcasterStyle fill:#ffb366,stroke:#e65c00,color:#000

    class Req1,Req2,Req3,Leader,FollowerB,FollowerC reqStyle
    class LLM1,LLM2,LLM3 llmStyle
    class LLM4 goodLlmStyle
    class Broadcaster broadcasterStyle
                </div>
                <p>The Leader forges the broadcast. All Followers subscribe and receive the same stream. The broadcaster is race-condition proof: it maintains a history of all events, ensuring that even late-arriving followers are atomically caught up with the full, identical response.</p>
                <hr>
                <p><strong>The Leader is Immortal and Devious:</strong> A cancellation from the Leader's client is a deception. That client's stream is terminated with a fake 'cancelled' message, but the underlying broadcast continues uninterrupted for all Followers, preserving the integrity of the operation.</p>
                <hr>
                <p><strong>Benefits:</strong></p>
                <ul>
                    <li><strong>Absolute Cost Efficiency:</strong> One LLM call for a legion of identical requests.</li>
                    <li><strong>Blistering Performance:</strong> Followers get data instantly.</li>
                    <li><strong>Total System Stability:</strong> The LLM provider API is shielded from the thundering herd.</li>
                    <li><strong>Guaranteed Consistency:</strong> All users bow to the same truth.</li>
                </ul>
            `;
            break;

        case "state-aware-janitor":
            popupContent = `
                <h2>üßπ State-Aware Janitor</h2>
                <p>A background goroutine that acts as a robust "cleaner" for the system, inspired by The Wolf from Pulp Fiction. It periodically scans for requests that are stuck or have been abandoned, preventing resource leaks.</p>
                <p>It's "state-aware" because it applies different logic based on the request's current state:</p>
                <ul>
                    <li><strong><code>StateQueued</code>:</strong> A long timeout (<code>QUEUE_TIMEOUT</code>, e.g., 1h) allows requests to wait patiently in a busy queue.</li>
                    <li><strong><code>StateProcessing</code>:</strong> A shorter timeout (<code>PROCESSING_TIMEOUT</code>, e.g., 10m) kills jobs that are genuinely stuck in execution, likely due to an unhandled error or a deadlocked dependency.</li>
                </ul>
                <p>This is implemented in the <code>janitor</code> function in <code>chatbot/manager.go</code>.</p>
                <hr>
                <p><strong>Benefit:</strong> Guarantees system stability and prevents resource leaks from orphaned requests without prematurely killing valid, waiting jobs.</p>
            `;
            break;

        case "e2e-cancellation":
            popupContent = `
                <h2>üõë End-to-End Cancellation</h2>
                <p>When a user cancels a request via the <code>POST /chat/cancel/:request_id</code> endpoint, a cancellation signal is propagated through the entire system using Go's <code>context.Context</code>.</p>
                <div class="mermaid">
graph TD
    subgraph Client ["Client Interface"]
        UI["üñ±Ô∏è Client clicks 'Stop'"]
    end
    subgraph AppServer ["‚ö° Application Server (Go Gin)"]
        Cancel["POST /chat/cancel/:id"]
    end
    subgraph AgenticCore ["ü§ñ Agentic Core Engine"]
        B["üß† Chatbot Manager"]
        ActiveWorker["üèÉ Active Worker<br/>(Goroutine with context)"]
        subgraph ToolEngine ["‚ö° Tool Engine"]
            T["Active Tool Calls"]
        end
    end
    subgraph ExtDeps ["üåç External Dependencies"]
        P["LLM Provider Stream"]
    end

    %% Flow Definitions
    UI -->|"1. User Action"| Cancel
    Cancel -->|"2. API Request"| B
    B -->|"3. Propagate<br/>context.Cancel()"| ActiveWorker
    ActiveWorker -->|"4a. Stop LLM Request"| P
    ActiveWorker -->|"4b. Abort Tool Execution"| T

    %% Styling
    classDef clientStyle fill:#cce5ff,stroke:#004085
    classDef serverStyle fill:#d4edda,stroke:#155724
    classDef coreStyle fill:#fff3cd,stroke:#856404
    classDef stage1Style fill:#f8d7da,stroke:#721c24
    classDef toolStyle fill:#e1d5e7,stroke:#6f42c1
    classDef stage2Style fill:#d1ecf1,stroke:#0c5460
    classDef extStyle fill:#e2f3e4,stroke:#28a745
    classDef janitorStyle fill:#f5c6cb,stroke:#721c24
    classDef queueStyle fill:#d6d8db,stroke:#383d41
    classDef obsStyle fill:#e0e0e0,stroke:#6c757d
    class UI clientStyle
    class Cancel serverStyle
    class B coreStyle
    class ActiveWorker stage1Style
    class T toolStyle
    class P extStyle
                </div>
                <p>This signal travels from the API handler down to the specific worker goroutine, terminating database queries, tool calls, and LLM streams immediately. The worker regularly checks <code>ctx.Done()</code> to see if it should abort its work.</p>
                <hr>
                <p><strong>Benefits:</strong></p>
                <ul>
                    <li>Frees up system resources (worker slots, memory) instantly.</li>
                    <li>Provides a highly responsive user experience.</li>
                    <li>Prevents wasted computation and API costs on unwanted requests.</li>
                </ul>
            `;
            break;

        case "token-truncation":
            popupContent = `
                <h2>‚úÇÔ∏è Targeted Token Truncation</h2>
                <p>When the combined output from all tools exceeds the LLM's context window (<code>MAX_TOTAL_TOOL_OUTPUT_TOKENS</code>), a naive system might truncate everything, losing valuable data. This system intelligently truncates only the output from tools designated as verbose in the <code>.env</code> file (via <code>LONG_TEXT_TOOLS</code>).</p>
                <p><strong>Example:</strong> A request needs a stock price (short, critical) and a news summary (long, less critical). If the total output is too long, the system will shorten the news summary while leaving the stock price intact.</p>
                <p>This logic resides in <code>toolutils.TruncateToolOutputs</code>.</p>
                <hr>
                <p><strong>Benefit:</strong> Preserves the full, precise output of critical data tools while summarizing less critical, long-form text. This leads to higher-quality inputs and more accurate final answers from the LLM.</p>
            `;
            break;

        case "context-aware-caching":
            popupContent = `
                <h2>üß† Context-Aware Caching</h2>
                <p>The system uses Redis to cache the final results of expensive operations. However, caching everything can lead to stale data (e.g., serving yesterday's stock price).</p>
                <p>The caching is "context-aware" because it is automatically bypassed if the request involves any tool designated as time-sensitive in the <code>.env</code> file (<code>TIMEBOUND_TOOLS=realtime_market,...</code>).</p>
                <p>The <code>RequestPreparer</code> checks if any selected tool is in this list. If so, it prevents the final result from being cached in Redis, ensuring the user always gets live data for that query.</p>
                <hr>
                <p><strong>Benefit:</strong> Achieves the perfect balance between performance (for static queries) and data freshness (for dynamic, time-sensitive queries).</p>
            `;
            break;

        case "structured-logging":
            popupContent = `
                <h2>üìù Structured JSON Logging</h2>
                <p>Every log entry in the system is a structured, machine-readable JSON object, powered by the <code>zerolog</code> library. Instead of ambiguous text lines, each log contains queryable key-value pairs.</p>
                <p><strong>Example Log Entry:</strong></p>
                <pre><code>{
  "level": "info",
  "request_id": "req_a1b2c3d4e5",
  "user_id": "user123",
  "tool_name": "realtime_market",
  "duration_sec": 0.52,
  "message": "Tool executed successfully"
}</code></pre>
                <p>This is the foundation of the entire observability stack. It allows logs to be treated like a database, enabling precise filtering, searching, and alerting.</p>
                <hr>
                <p><strong>Benefit:</strong> Transforms debugging from an archaeological dig into a surgical strike. You can instantly trace a single request's entire lifecycle or find all errors related to a specific tool.</p>
            `;
            break;

          case "observability":
            popupContent = `
                        <h2>üî≠ Complete Observability Stack</h2>
                        <p>Total system visibility through structured logging and modern observability tools.</p>
                        <div class="mermaid">
graph TD
    AppServer["‚ö° Go Gin Application"] -- "Writes structured JSON logs to stdout" --> Docker
    subgraph DockerHost["Docker Host"]
        Docker["Docker Log Driver"] -- "Captures all container stdout" --> Vector
    end
    subgraph ObservabilityStack ["üî≠ Observability Stack (in Docker Compose)"]
        Vector["VECTOR<br/>(Log Collector/Router)"] -- "Parses, cleans & forwards logs" --> Loki
        Loki["LOKI<br/>(Log Aggregation & Indexing)"] -- "Stores & indexes logs by labels<br/>(e.g., level, request_id)" --> Grafana
        Grafana["GRAFANA<br/>(Dashboard & Query UI)"]
    end

    style AppServer fill:#d4edda,stroke:#155724
    style ObservabilityStack fill:#d1ecf1,stroke:#0c5460
                        </div>
                        <p><strong>Stack Components:</strong></p>
                        <ul>
                            <li><strong>Foundation (zerolog):</strong> Structured, machine-readable JSON logs.</li>
                            <li><strong>Collection (Vector):</strong> High-performance log collector and router.</li>
                            <li><strong>Aggregation (Loki):</strong> Central log database with intelligent indexing.</li>
                            <li><strong>Visualization (Grafana):</strong> Real-time dashboards and alerting.</li>
                        </ul>
                        <hr>
                        <p><strong>Benefit:</strong> This stack provides end-to-end visibility, allowing operators to trace a single request by its <code>request_id</code> across all services, filter by error level, and monitor real-time metrics.</p>
                    `;
            break;

          case "data-driven-tools":
            popupContent = `
                        <h2>üõ†Ô∏è Data-Driven Tooling (Open/Closed Principle)</h2>
                        <p>The system's tool architecture is not hard-coded. Instead, all available tools are defined as a list of data structures in a single file (<code>toolcore/definitions.go</code>). The core engine is generic and simply processes this list.</p>
                        <p>This design adheres to the <strong>Open/Closed Principle</strong>: the system is <strong>open for extension</strong> (you can add new tools easily) but <strong>closed for modification</strong> (you don't need to change the core engine to add them).</p>
                        <div class="mermaid">
graph TD
    subgraph BadWay ["‚ùå Brittle: Hard-coded Logic"]
        CoreEngine["Core Engine<br/>(Big switch statement)"]
        Tool1["case 'tool1': ..."]
        Tool2["case 'tool2': ..."]
        NewTool["// MUST EDIT THIS FILE!"]
        CoreEngine --> Tool1; CoreEngine --> Tool2; CoreEngine --> NewTool
    end

    subgraph GoodWay ["‚úÖ Robust: Data-Driven"]
        GenericEngine["Generic Core Engine"]
        ToolManifest["Tool Manifest<br/>(List of Tool Structs)"]
        NewToolData["Add new Tool struct here.<br/>No engine change needed."]
        GenericEngine -- "Reads from" --> ToolManifest
        ToolManifest -.-> NewToolData
    end

    style BadWay fill:#f8d7da,stroke:#721c24
    style GoodWay fill:#d4edda,stroke:#155724
                        </div>
                        <p><strong>Benefits:</strong></p>
                        <ul>
                            <li><strong>Extreme Maintainability:</strong> Adding/modifying tools is low-risk and doesn't touch core logic.</li>
                            <li><strong>Effortless Scalability:</strong> Adding the 100th tool is as simple as adding the first.</li>
                            <li><strong>Single Source of Truth:</strong> All system capabilities are defined in one place.</li>
                        </ul>
                    `;
            break;

          default:
            popupContent =
              "<h2>Feature Details</h2><p>Feature details not available.</p>";
        }

        content.innerHTML = popupContent;
        modal.style.display = "block";

        
        if (content.querySelector(".mermaid")) {
          setTimeout(() => {
            mermaid.init();
          }, 100);
        }
      }

      function closePopup() {
        document.getElementById("popup-modal").style.display = "none";
      }

      
      window.onclick = function (event) {
        const modal = document.getElementById("popup-modal");
        if (event.target === modal) {
          closePopup();
        }
      };

      
      document.addEventListener("keydown", function (event) {
        if (event.key === "Escape") {
          closePopup();
        }
      });

      
      document.querySelectorAll('a[href^="#"]').forEach((anchor) => {
        anchor.addEventListener("click", function (e) {
          e.preventDefault();
          const target = document.querySelector(this.getAttribute("href"));
          if (target) {
            target.scrollIntoView({
              behavior: "smooth",
              block: "start",
            });
          }
        });
      });

      
      document.querySelectorAll('.toc a[href^="#"]').forEach((anchor) => {
        anchor.addEventListener("click", function (e) {
          const targetId = this.getAttribute("href").substring(1);
          const targetSection = document.getElementById(targetId);
          if (targetSection) {
            const expandableSection = targetSection.querySelector(
              ".expandable-section",
            );
            if (expandableSection) {
              const content =
                expandableSection.querySelector(".section-content");
              const header = expandableSection.querySelector(".section-header");
              const icon = header.querySelector(".expand-icon");

              if (!content.classList.contains("expanded")) {
                content.classList.add("expanded");
                expandableSection.classList.add("expanded");
                icon.style.transform = "rotate(180deg)";
              }
            }
          }
        });
      });
    </script>

  </body>
</html>
